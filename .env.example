# MAGSAG HTTP API Configuration
# Copy this file to .env and customize values for your environment

# ============================================================================
# Core API Settings
# ============================================================================

# Server host and port (for uvicorn)
MAGSAG_API_HOST=0.0.0.0
MAGSAG_API_PORT=8000

# API prefix for all endpoints
MAGSAG_API_PREFIX=/api/v1

# Enable debug mode (detailed logs, hot reload)
MAGSAG_API_DEBUG=false

# Base directory for run artifacts
MAGSAG_RUNS_BASE_DIR=.runs/agents

# ============================================================================
# Authentication & Security
# ============================================================================

# API key for authentication
# Generate with: openssl rand -hex 32
# Leave commented out to disable authentication (development only)
# MAGSAG_API_KEY=your-secret-key-here

# CORS allowed origins
# For development: ["*"]
# For production: ["https://yourdomain.com","https://app.yourdomain.com"]
MAGSAG_CORS_ORIGINS=["*"]

# Allow credentials in CORS requests
MAGSAG_CORS_ALLOW_CREDENTIALS=false

# ============================================================================
# Rate Limiting
# ============================================================================

# Maximum requests per second per client IP
# Comment out or leave empty to disable rate limiting
# MAGSAG_RATE_LIMIT_QPS=10

# Redis URL for distributed rate limiting (multi-process deployments)
# Format: redis://localhost:6379/0
# Comment out or leave empty to use in-memory rate limiter
# MAGSAG_REDIS_URL=redis://localhost:6379/0

# ============================================================================
# Anthropic API Integration
# ============================================================================

# Anthropic API key for batch processing and optimization
# Get your API key from: https://console.anthropic.com/settings/keys
# Required for: Batch Manager, AI-powered agents
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# ============================================================================
# GitHub Integration
# ============================================================================

# Webhook signature verification secret
# Set the same value in GitHub webhook configuration
# MAGSAG_GITHUB_WEBHOOK_SECRET=your-webhook-secret

# GitHub personal access token for posting comments
# Required scopes: repo (for private repos) or public_repo (for public repos)
# MAGSAG_GITHUB_TOKEN=ghp_your_token_here

# ============================================================================
# LLM Provider Configuration
# ============================================================================

# Unified Provider Selection
# Override provider for all tasks (takes precedence over routing policies)
# Supported values: openai, anthropic, google, local, compat
# Leave commented to use routing policy defaults
# MAGSAG_PROVIDER=openai

# Optional: Override model for all tasks (provider-specific)
# Examples:
#   - OpenAI: gpt-4, gpt-3.5-turbo
#   - Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229
#   - Google: gemini-1.5-pro, gemini-2.0-flash
# Leave commented to use routing policy defaults
# MAGSAG_MODEL=gpt-4

# OpenAI API key for provider integration
# Required for OpenAI provider and batch processing
# Get your key at: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API key for Claude models
# Get your key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# Google Generative AI Provider
# API key for Google's generative AI services
# Get your API key from: https://makersuite.google.com/app/apikey
# GOOGLE_API_KEY=your-google-api-key-here

# SDK type to use: "google-generativeai" (legacy) or "google-genai" (new)
# Default: google-generativeai
# GOOGLE_SDK_TYPE=google-generativeai

# Model name to use (e.g., gemini-1.5-pro, gemini-2.0-flash)
# Default: gemini-1.5-pro
# GOOGLE_MODEL_NAME=gemini-1.5-pro

# Local LLM Provider Settings (vLLM, Ollama)
# Base URL for OpenAI-compatible local LLM server (must end with /)
# Common endpoints:
#   - vLLM: http://localhost:8000/v1/
#   - Ollama: http://localhost:11434/v1/
# MAGSAG_LOCAL_LLM_BASE_URL=http://localhost:8000/v1/

# API key for local LLM server (optional, some servers require it)
# MAGSAG_LOCAL_LLM_API_KEY=

# Request timeout in seconds for local LLM calls
# MAGSAG_LOCAL_LLM_TIMEOUT=60.0

# ============================================================================
# Observability & Monitoring
# ============================================================================

# OpenTelemetry Tracing
# Enable distributed tracing with OpenTelemetry
MAGSAG_OTEL_TRACING_ENABLED=false

# OpenTelemetry Metrics
# Enable metrics collection with OpenTelemetry
MAGSAG_OTEL_METRICS_ENABLED=false

# Service name for traces and metrics
MAGSAG_SERVICE_NAME=magsag

# OTLP endpoint for traces and metrics
# For local Jaeger: http://localhost:4318
# For production: your OTLP collector endpoint
# MAGSAG_OTLP_ENDPOINT=http://localhost:4318

# Langfuse Integration
# Enable Langfuse for LLM observability
MAGSAG_LANGFUSE_ENABLED=false

# Langfuse API credentials
# Get these from https://cloud.langfuse.com or your self-hosted instance
# LANGFUSE_PUBLIC_KEY=pk_your_public_key
# LANGFUSE_SECRET_KEY=sk_your_secret_key

# Langfuse host (default: https://cloud.langfuse.com)
# For self-hosted: https://your-langfuse-instance.com
# LANGFUSE_HOST=https://cloud.langfuse.com

# Cost Tracking
# Paths for cost tracking storage
# MAGSAG_COST_JSONL_PATH=.magsag/costs.jsonl

# ============================================================================
# MCP Provider Credentials
# ============================================================================

# Supabase (CI-only automation should use PAT + project_ref)
MAGSAG_MCP_SUPABASE_PROJECT_REF=
MAGSAG_MCP_SUPABASE_ACCESS_TOKEN=
MAGSAG_MCP_SUPABASE_READONLY=true

# GitHub (use OAuth locally, PATs are fallback for CI/headless)
MAGSAG_MCP_GITHUB_PAT=

# Obsidian Local REST API integration
OBSIDIAN_API_KEY=
OBSIDIAN_HOST=127.0.0.1
OBSIDIAN_PORT=27124
# MAGSAG_COST_DB_PATH=.magsag/costs.db
# MAGSAG_COST_SQLITE_ENABLED=true

# ============================================================================
# Semantic Cache Configuration
# ============================================================================

# Cache backend type (faiss or redis)
# FAISS: Local in-memory cache with approximate nearest neighbor search
# Redis: Distributed cache with Redis Vector Index (requires Redis Stack)
MAGSAG_CACHE_BACKEND=faiss

# Embedding dimension (must match your embedding model)
# Common values: 768 (BERT), 1536 (OpenAI), 384 (MiniLM)
MAGSAG_CACHE_DIMENSION=768

# Redis Vector Index configuration (only used when backend=redis)
# MAGSAG_CACHE_REDIS_URL=redis://localhost:6379
# MAGSAG_CACHE_REDIS_INDEX_NAME=magsag_cache

# FAISS index configuration (only used when backend=faiss)
# Index types: Flat (exact search), IVFFlat (approximate nearest neighbor)
# Note: Flat is recommended for <10k entries, IVFFlat for larger datasets
MAGSAG_CACHE_FAISS_INDEX_TYPE=Flat
MAGSAG_CACHE_FAISS_NLIST=100

# ============================================================================
# Production Recommendations
# ============================================================================
# These settings are STRONGLY RECOMMENDED for production deployments.
# Uncomment and customize these values to enable production-ready security:
#
# REQUIRED: Authentication & Authorization
# Generate a strong API key: openssl rand -hex 32
# MAGSAG_API_KEY=<generate-strong-key-here>
#
# REQUIRED: Rate Limiting
# Enables token-bucket rate limiter to prevent abuse
# MAGSAG_RATE_LIMIT_QPS=10
#
# RECOMMENDED: Distributed Rate Limiting (for multi-process/multi-instance)
# Requires Redis Stack or Redis with RedisJSON module
# Fail-open behavior: If Redis connection fails, rate limiting uses in-memory fallback
# MAGSAG_REDIS_URL=redis://localhost:6379
#
# REQUIRED: CORS Configuration
# Replace with your actual frontend/client domains
# MAGSAG_CORS_ORIGINS=["https://yourdomain.com","https://app.yourdomain.com"]
# MAGSAG_CORS_ALLOW_CREDENTIALS=false
#
# RECOMMENDED: GitHub Webhook Security (if using GitHub integration)
# Generate a strong secret: openssl rand -hex 32
# MAGSAG_GITHUB_WEBHOOK_SECRET=<generate-strong-secret-here>
# MAGSAG_GITHUB_TOKEN=ghp_your_token_here
#
# RECOMMENDED: Disable Debug Mode in Production
# MAGSAG_API_DEBUG=false
#
# RECOMMENDED: Enable Observability (OpenTelemetry or Langfuse)
# MAGSAG_OTEL_TRACING_ENABLED=true
# MAGSAG_OTLP_ENDPOINT=http://localhost:4318
#
# ============================================================================
# Production Deployment Example
# ============================================================================
# Complete example configuration for production deployment:
#
# MAGSAG_API_HOST=0.0.0.0
# MAGSAG_API_PORT=8000
# MAGSAG_API_DEBUG=false
# MAGSAG_API_KEY=your-generated-secret-key-here
# MAGSAG_CORS_ORIGINS=["https://yourdomain.com","https://app.yourdomain.com"]
# MAGSAG_CORS_ALLOW_CREDENTIALS=false
# MAGSAG_RATE_LIMIT_QPS=10
# MAGSAG_REDIS_URL=redis://redis:6379/0
# MAGSAG_GITHUB_WEBHOOK_SECRET=your-webhook-secret
# MAGSAG_GITHUB_TOKEN=ghp_your_token_here
# MAGSAG_OTEL_TRACING_ENABLED=true
# MAGSAG_OTLP_ENDPOINT=http://otel-collector:4318
